{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YOuo4tLQAT8B_qTky_4M8uhc68PSTrps",
      "authorship_tag": "ABX9TyNfL727dXs7k5iW5mtawASq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharmakhushi9757/Mood-Based-Music-Recommendation-System/blob/main/EMO_PLAYER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHvtJsLGpuoc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('default')\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import layers , models, optimizers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import ResNet50V2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cRR6pgxC90Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/MyDrive/FER_2013/train/'\n",
        "test_dir = '/content/drive/MyDrive/FER_2013/test/'\n",
        "\n",
        "def Classes_Count( path, name):\n",
        "    Classes_Dict = {}\n",
        "    for Class in os.listdir(path):\n",
        "        Full_Path = path + Class\n",
        "        Classes_Dict[Class] = len(os.listdir(Full_Path))\n",
        "    df = pd.DataFrame(Classes_Dict, index=[name])\n",
        "    return df\n",
        "\n",
        "Train_Count = Classes_Count(train_dir, 'Train').transpose().sort_values(by=\"Train\", ascending=False)\n",
        "Test_Count = Classes_Count(test_dir, 'Test').transpose().sort_values(by=\"Test\", ascending=False)"
      ],
      "metadata": {
        "id": "hRRm5Vc90tiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([Train_Count,Test_Count] , axis=1)"
      ],
      "metadata": {
        "id": "Lbom62S60zDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_Count.plot(kind='barh')"
      ],
      "metadata": {
        "id": "i3lLqREc04UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_Count.plot(kind='barh')"
      ],
      "metadata": {
        "id": "UzuZRsaM06G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('default')\n",
        "plt.figure(figsize = (25, 8))\n",
        "image_count = 1\n",
        "BASE_URL = '/content/drive/MyDrive/FER_2013/train/'\n",
        "\n",
        "for directory in os.listdir(BASE_URL):\n",
        "    if directory[0] != '.':\n",
        "        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n",
        "            if i == 1:\n",
        "                break\n",
        "            else:\n",
        "                fig = plt.subplot(1, 7, image_count)\n",
        "                image_count += 1\n",
        "                image = cv2.imread(BASE_URL + directory + '/' + file)\n",
        "                plt.imshow(image)\n",
        "                plt.title(directory, fontsize = 20)"
      ],
      "metadata": {
        "id": "e_cpSJI6078C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape = 48\n",
        "batch_size = -1\n",
        "train_data_path = '/content/drive/MyDrive/FER_2013/train/'\n",
        "test_data_path = '/content/drive/MyDrive/FER_2013/test/'"
      ],
      "metadata": {
        "id": "Gm2HIJ2w0_N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_preprocessor = ImageDataGenerator(\n",
        "        rescale = 1 / 255.,\n",
        "        # Data Augmentation\n",
        "        rotation_range=10,\n",
        "        zoom_range=0.2,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,                                        \n",
        "        fill_mode='nearest',\n",
        "    )\n",
        "\n",
        "\n",
        "test_preprocessor = ImageDataGenerator(\n",
        "    rescale = 1 / 255.,\n",
        ")\n",
        "\n",
        "train_data = train_preprocessor.flow_from_directory(\n",
        "    train_data_path,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(img_shape,img_shape),\n",
        "    color_mode='rgb', \n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    subset='training', \n",
        ")\n",
        "\n",
        "\n",
        "test_data = test_preprocessor.flow_from_directory(\n",
        "    test_data_path,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(img_shape,img_shape),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "metadata": {
        "id": "xQWcBnJC1Bzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Create_CNN_Model():\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    #CNN1\n",
        "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=(img_shape, img_shape, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64,(3,3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    #CNN2\n",
        "    model.add(Conv2D(64, (3,3), activation='relu', ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128,(3,3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    #CNN3\n",
        "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256,(3,3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    \n",
        "    #Output\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(7,activation='softmax'))\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "m0UWBYYr1GoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_Model = Create_CNN_Model()\n",
        "\n",
        "CNN_Model.summary()\n",
        "\n",
        "CNN_Model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYdBHgnK1M43",
        "outputId": "be538fe7-931e-4718-d12f-9210d433c524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 46, 46, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 46, 46, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 46, 46, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 46, 46, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 23, 23, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 23, 23, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 21, 21, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 21, 21, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 21, 21, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 21, 21, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 11, 11, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 11, 11, 128)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 9, 9, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 9, 9, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 9, 9, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 9, 9, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 5, 5, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 5, 5, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6400)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              6554624   \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 32)               128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 7)                 231       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,837,895\n",
            "Trainable params: 7,832,519\n",
            "Non-trainable params: 5,376\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Callback Checkpoint\n",
        "checkpoint_path = \"CNN_Model_Checkpoint\"\n",
        "\n",
        "Checkpoint = ModelCheckpoint(checkpoint_path, monitor=\"val_accuracy\", save_best_only=True)\n",
        "\n",
        "# Create Early Stopping Callback to monitor the accuracy\n",
        "Early_Stopping = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True, verbose=1)\n",
        "\n",
        "# Create ReduceLROnPlateau Callback to reduce overfitting by decreasing learning rate\n",
        "Reducing_LR = tf.keras.callbacks.ReduceLROnPlateau( monitor='val_loss',\n",
        "                                                  factor=0.2,\n",
        "                                                  patience=2,\n",
        "#                                                   min_lr=0.000005,\n",
        "                                                  verbose=1)\n",
        "\n",
        "callbacks = [Early_Stopping, Reducing_LR]\n",
        "\n",
        "steps_per_epoch = train_data.n // train_data.batch_size\n",
        "validation_steps = test_data.n // test_data.batch_size"
      ],
      "metadata": {
        "id": "Z0Yz1ZxG1PNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_history = CNN_Model.fit( train_data , validation_data= test_data , epochs=50, batch_size= batch_size,\n",
        "                            callbacks=callbacks, steps_per_epoch= steps_per_epoch, validation_steps=validation_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI1IBekC1TZh",
        "outputId": "5c9d8483-7b7a-42fb-d249-5113377077b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            " 85/449 [====>.........................] - ETA: 3:53:07 - loss: 2.3595 - accuracy: 0.1732"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_Score = CNN_Model.evaluate(test_data)\n",
        "\n",
        "print(\"    Test Loss: {:.5f}\".format(CNN_Score[0]))\n",
        "print(\"Test Accuracy: {:.2f}%\".format(CNN_Score[1] * 100))"
      ],
      "metadata": {
        "id": "Xsv8bt9DAFaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_curves(history):\n",
        "\n",
        "    loss = history.history[\"loss\"]\n",
        "    val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "    accuracy = history.history[\"accuracy\"]\n",
        "    val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "    epochs = range(len(history.history[\"loss\"]))\n",
        "\n",
        "    plt.figure(figsize=(15,5))\n",
        "\n",
        "    #plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, label = \"training_loss\")\n",
        "    plt.plot(epochs, val_loss, label = \"val_loss\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    #plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracy, label = \"training_accuracy\")\n",
        "    plt.plot(epochs, val_accuracy, label = \"val_accuracy\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.legend()\n",
        "  \n",
        "  #plt.tight_layout()"
      ],
      "metadata": {
        "id": "tSdfIdez__15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_curves(CNN_history)"
      ],
      "metadata": {
        "id": "Ki2eXdjF_8yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_Predictions = CNN_Model.predict(test_data)\n",
        "\n",
        "# Choosing highest probalbilty class in every prediction \n",
        "CNN_Predictions = np.argmax(CNN_Predictions, axis=1)"
      ],
      "metadata": {
        "id": "2H2lKHtm_4Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.class_indices"
      ],
      "metadata": {
        "id": "EUsVWMJB_2FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "fig, ax= plt.subplots(figsize=(15,10))\n",
        "\n",
        "cm=confusion_matrix(test_data.labels, CNN_Predictions)\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels',fontsize=15, fontweight='bold')\n",
        "ax.set_ylabel('True labels', fontsize=15, fontweight='bold')\n",
        "ax.set_title('CNN Confusion Matrix', fontsize=20, fontweight='bold')"
      ],
      "metadata": {
        "id": "x8nFFmmt_xvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specifing new image shape for resnet\n",
        "img_shape = 224\n",
        "batch_size = 64\n",
        "train_data_path = '/content/drive/MyDrive/FER_2013/train/'\n",
        "test_data_path = '/content/drive/MyDrive/FER_2013/test/'"
      ],
      "metadata": {
        "id": "ORapVn5A_vOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_preprocessor = ImageDataGenerator(\n",
        "        rescale = 1 / 255.,\n",
        "        rotation_range=10,\n",
        "        zoom_range=0.2,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,                                        \n",
        "        fill_mode='nearest',\n",
        "    )\n",
        "\n",
        "\n",
        "test_preprocessor = ImageDataGenerator(\n",
        "    rescale = 1 / 255.,\n",
        ")\n",
        "\n",
        "train_data = train_preprocessor.flow_from_directory(\n",
        "    train_data_path,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(img_shape,img_shape),\n",
        "    color_mode='rgb',\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    subset='training', \n",
        ")\n",
        "\n",
        "test_data = test_preprocessor.flow_from_directory(\n",
        "    test_data_path,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(img_shape,img_shape),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "metadata": {
        "id": "1T4GWm931vO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 224,224,3\n",
        "ResNet50V2 = tf.keras.applications.ResNet50V2(input_shape=(224, 224, 3),\n",
        "                                               include_top= False,\n",
        "                                               weights='imagenet'\n",
        "                                               )\n",
        "\n",
        "#ResNet50V2.summary()"
      ],
      "metadata": {
        "id": "7SnxaboI1wD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freezing all layers except last 50\n",
        "\n",
        "ResNet50V2.trainable = True\n",
        "\n",
        "for layer in ResNet50V2.layers[:-50]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "Y95X02s81ya-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Create_ResNet50V2_Model():\n",
        "\n",
        "    model = Sequential([\n",
        "                      ResNet50V2,\n",
        "                      Dropout(.25),\n",
        "                      BatchNormalization(),\n",
        "                      Flatten(),\n",
        "                      Dense(64, activation='relu'),\n",
        "                      BatchNormalization(),\n",
        "                      Dropout(.5),\n",
        "                      Dense(7,activation='softmax')\n",
        "                    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "NHm9d2Bj10Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50V2_Model = Create_ResNet50V2_Model()\n",
        "\n",
        "ResNet50V2_Model.summary()\n",
        "\n",
        "ResNet50V2_Model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "W3R5V8Ms12y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Callback Checkpoint\n",
        "checkpoint_path = \"ResNet50V2_Model_Checkpoint\"\n",
        "\n",
        "Checkpoint = ModelCheckpoint(checkpoint_path, monitor=\"val_accuracy\", save_best_only=True)\n",
        "\n",
        "# Create Early Stopping Callback to monitor the accuracy\n",
        "Early_Stopping = EarlyStopping(monitor = 'val_accuracy', patience = 7, restore_best_weights = True, verbose=1)\n",
        "\n",
        "# Create ReduceLROnPlateau Callback to reduce overfitting by decreasing learning\n",
        "Reducing_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                                  factor=0.2,\n",
        "                                                  patience=2,\n",
        "#                                                   min_lr=0.00005,\n",
        "                                                  verbose=1)\n",
        "\n",
        "callbacks = [Early_Stopping, Reducing_LR]\n",
        "\n",
        "steps_per_epoch = train_data.n // train_data.batch_size\n",
        "validation_steps = test_data.n // test_data.batch_size"
      ],
      "metadata": {
        "id": "ff8Hgn7Z15rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50V2_history = ResNet50V2_Model.fit(train_data ,validation_data = test_data , epochs=30, batch_size=batch_size,\n",
        "                                         callbacks = callbacks, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps)"
      ],
      "metadata": {
        "id": "JXd8QyNG18yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50V2_Score = ResNet50V2_Model.evaluate(test_data)\n",
        "\n",
        "print(\"    Test Loss: {:.5f}\".format(ResNet50V2_Score[0]))\n",
        "print(\"Test Accuracy: {:.2f}%\".format(ResNet50V2_Score[1] * 100))"
      ],
      "metadata": {
        "id": "89zmh_WM1_ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_curves(ResNet50V2_history)"
      ],
      "metadata": {
        "id": "a70bA6II2B8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50V2_Predictions = ResNet50V2_Model.predict(test_data)\n",
        "â€‹\n",
        "# Choosing highest probalbilty class in every prediction \n",
        "ResNet50V2_Predictions = np.argmax(ResNet50V2_Predictions, axis=1)"
      ],
      "metadata": {
        "id": "R3G9u7AG2FtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig , ax= plt.subplots(figsize=(15,10))\n",
        "\n",
        "cm=confusion_matrix(test_data.labels, ResNet50V2_Predictions)\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels',fontsize=15, fontweight='bold')\n",
        "ax.set_ylabel('True labels', fontsize=15, fontweight='bold')\n",
        "ax.set_title('ResNet50V2 Confusion Matrix', fontsize=20, fontweight='bold')"
      ],
      "metadata": {
        "id": "l_HJWzZn2GnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Emotion_Classes = ['Angry', \n",
        "                  'Disgust', \n",
        "                  'Fear', \n",
        "                  'Happy', \n",
        "                  'Neutral', \n",
        "                  'Sad', \n",
        "                  'Surprise']"
      ],
      "metadata": {
        "id": "y3ULwBa42JuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffling Test Data to show diffrent classes\n",
        "test_preprocessor = ImageDataGenerator(\n",
        "        rescale = 1 / 255.,\n",
        "    )\n",
        "\n",
        "test_generator = test_preprocessor.flow_from_directory(\n",
        "    test_data_path,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(img_shape,img_shape),\n",
        "    color_mode=\"rgb\",\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "metadata": {
        "id": "QpIx4pLF2Mfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display 10 random pictures from the dataset with their labels\n",
        "\n",
        "Random_batch = np.random.randint(0, len(test_generator) - 1)\n",
        "\n",
        "Random_Img_Index = np.random.randint(0, batch_size - 1 , 10)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(25, 10),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "\n",
        "    Random_Img = test_generator[Random_batch][0][Random_Img_Index[i]]\n",
        "\n",
        "    Random_Img_Label = np.argmax(test_generator[Random_batch][1][Random_Img_Index[i]])\n",
        "\n",
        "    Model_Prediction = np.argmax(CNN_Model.predict( tf.expand_dims(Random_Img, axis=0) , verbose=0))\n",
        "\n",
        "    ax.imshow(Random_Img)\n",
        "\n",
        "    if Emotion_Classes[Random_Img_Label] == Emotion_Classes[Model_Prediction]:\n",
        "          color = \"green\"\n",
        "    else:\n",
        "          color = \"red\"\n",
        "    ax.set_title(f\"True: {Emotion_Classes[Random_Img_Label]}\\nPredicted: {Emotion_Classes[Model_Prediction]}\", color=color)\n",
        "plt.show()\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "pSMTiLFJ2Pxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display 10 random pictures from the dataset with their labels\n",
        "\n",
        "Random_batch = np.random.randint(0, len(test_generator) - 1)\n",
        "\n",
        "Random_Img_Index = np.random.randint(0, batch_size - 1 , 10)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(25, 10),\n",
        "                        subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "\n",
        "    Random_Img = test_generator[Random_batch][0][Random_Img_Index[i]]\n",
        "\n",
        "    Random_Img_Label = np.argmax(test_generator[Random_batch][1][Random_Img_Index[i]])\n",
        "\n",
        "    Model_Prediction = np.argmax(ResNet50V2_Model.predict( tf.expand_dims(Random_Img, axis=0) , verbose=0))\n",
        "\n",
        "    ax.imshow(Random_Img)\n",
        "\n",
        "    if Emotion_Classes[Random_Img_Label] == Emotion_Classes[Model_Prediction]:\n",
        "          color = \"green\"\n",
        "    else:\n",
        "          color = \"red\"\n",
        "    ax.set_title(f\"True: {Emotion_Classes[Random_Img_Label]}\\nPredicted: {Emotion_Classes[Model_Prediction]}\", color=color)\n",
        "plt.show()\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "V1Frv3LQ2TPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MUSIC PLAYER**"
      ],
      "metadata": {
        "id": "5G536fAS2c0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Music_Player = pd.read_csv(\"/content/drive/MyDrive/Spotify_mood/data_moods.csv\")\n",
        "Music_Player = Music_Player[['name','artist','mood','popularity']]\n",
        "Music_Player.head()"
      ],
      "metadata": {
        "id": "bJGchXDl2WWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Music_Player[\"mood\"].value_counts()"
      ],
      "metadata": {
        "id": "jPoW-O8K2p5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Music_Player[\"popularity\"].value_counts()"
      ],
      "metadata": {
        "id": "YsEGSOHi2vhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Play = Music_Player[Music_Player['mood'] =='Calm' ]\n",
        "Play = Play.sort_values(by=\"popularity\", ascending=False)\n",
        "Play = Play[:5].reset_index(drop=True)\n",
        "display(Play)"
      ],
      "metadata": {
        "id": "6gwGngtZ2yvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making Songs Recommendations Based on Predicted Class\n",
        "def Recommend_Songs(pred_class):\n",
        "    \n",
        "    if( pred_class=='Disgust' ):\n",
        "\n",
        "        Play = Music_Player[Music_Player['mood'] =='Sad' ]\n",
        "        Play = Play.sort_values(by=\"popularity\", ascending=False)\n",
        "        Play = Play[:5].reset_index(drop=True)\n",
        "        display(Play)\n",
        "\n",
        "    if( pred_class=='Happy' or pred_class=='Sad' ):\n",
        "\n",
        "        Play = Music_Player[Music_Player['mood'] =='Happy' ]\n",
        "        Play = Play.sort_values(by=\"popularity\", ascending=False)\n",
        "        Play = Play[:5].reset_index(drop=True)\n",
        "        display(Play)\n",
        "\n",
        "    if( pred_class=='Fear' or pred_class=='Angry' ):\n",
        "\n",
        "        Play = Music_Player[Music_Player['mood'] =='Calm' ]\n",
        "        Play = Play.sort_values(by=\"popularity\", ascending=False)\n",
        "        Play = Play[:5].reset_index(drop=True)\n",
        "        display(Play)\n",
        "\n",
        "    if( pred_class=='Surprise' or pred_class=='Neutral' ):\n",
        "\n",
        "        Play = Music_Player[Music_Player['mood'] =='Energetic' ]\n",
        "        Play = Play.sort_values(by=\"popularity\", ascending=False)\n",
        "        Play = Play[:5].reset_index(drop=True)\n",
        "        display(Play)"
      ],
      "metadata": {
        "id": "aLmjKHUO209w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
        "    \n",
        "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")    "
      ],
      "metadata": {
        "id": "XrQgtOyL2-Pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prep_image(filename, img_shape = 224):\n",
        "\n",
        "    img = cv2.imread(filename)\n",
        "\n",
        "    GrayImg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    faces = faceCascade.detectMultiScale(GrayImg, 1.1, 4)\n",
        "    \n",
        "    for x,y,w,h in faces:\n",
        "        \n",
        "        roi_GrayImg = GrayImg[ y: y + h , x: x + w ]\n",
        "        roi_Img = img[ y: y + h , x: x + w ]\n",
        "        \n",
        "        cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
        "        \n",
        "        plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
        "        \n",
        "        faces = faceCascade.detectMultiScale(roi_Img, 1.1, 4)\n",
        "        \n",
        "        if len(faces) == 0:\n",
        "            print(\"No Faces Detected\")\n",
        "        else:\n",
        "            for (ex, ey, ew, eh) in faces:\n",
        "                img = roi_Img[ ey: ey+eh , ex: ex+ew ]\n",
        "    \n",
        "    RGBImg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    RGBImg= cv2.resize(RGBImg,(img_shape,img_shape))\n",
        "\n",
        "    RGBImg = RGBImg/255.\n",
        "\n",
        "    return RGBImg"
      ],
      "metadata": {
        "id": "or0yyfEt3Cf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot(filename, class_names):\n",
        "\n",
        "    # Import the target image and preprocess it\n",
        "    img = load_and_prep_image(filename)\n",
        "\n",
        "    # Make a prediction\n",
        "    pred = ResNet50V2_Model.predict(np.expand_dims(img, axis=0))\n",
        "\n",
        "    # Get the predicted class\n",
        "    pred_class = class_names[pred.argmax()]\n",
        "\n",
        "    # Plot the image and predicted class\n",
        "    #plt.imshow(img)\n",
        "    plt.title(f\"Prediction: {pred_class}\")\n",
        "    plt.axis(False);\n",
        "    \n",
        "    Recommend_Songs(pred_class)"
      ],
      "metadata": {
        "id": "9FFwYThK3HJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_plot(\"../input/fer2013/test/sad/PrivateTest_13472479.jpg\", Emotion_Classes) # with CNN"
      ],
      "metadata": {
        "id": "Ka_--pOA3Kkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading Image to Test On\n",
        "!wget -c \"https://pbs.twimg.com/media/EEY3RFFWwAAc-qm.jpg\" -O sad.jpg"
      ],
      "metadata": {
        "id": "KNRONuxs3NTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_plot(\"./happy.jpg\", Emotion_Classes) # with CNN"
      ],
      "metadata": {
        "id": "xBGsmsIk3UhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_plot(\"../input/fer2013/test/angry/PrivateTest_22126718.jpg\", Emotion_Classes) # with ResNet50V2"
      ],
      "metadata": {
        "id": "yY6y9cTs3URz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading Image to Test On\n",
        "!wget -c \"https://pbs.twimg.com/profile_images/758370732413947904/xYB5Q3FY_400x400.jpg\" -O happy.jpg "
      ],
      "metadata": {
        "id": "vEDZVTpM3UD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_plot(\"./sad.jpg\", Emotion_Classes) # with ResNet50V2"
      ],
      "metadata": {
        "id": "VLq5BgQk3T2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_Model.save(\"CNN_Model.h5\")\n",
        "\n",
        "ResNet50V2_Model.save(\"ResNet50V2_Model.h5\")"
      ],
      "metadata": {
        "id": "m4cEtg0Q3fjV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}